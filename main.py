import openai
import gradio as gr
from gtts import gTTS
from speech_to_text_VI import asr_gg
from IPython.display import Audio, HTML
from textToSpeech import TextToSpeech
from textToSpeech_2 import TextToSpeech2
import os
from uploadFileToDrive import upload_basic
from googleAPILib import Service
from shareFile import shareFile
from getViewLink import getViewLink
from playsound import playsound

# Thi·∫øt l·∫≠p API key c·ªßa OpenAI
openai.api_key = "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"

# Thi·∫øt l·∫≠p c√°c th√¥ng tin ƒë·ªÉ g·ªçi API
model_engine = "text-davinci-003"
temperature = 0.2
max_tokens = 1000
generate_prompt = '''B·∫°n l√† v·ªã thi·ªÅn s∆∞ Ph·∫≠t Ph√°p t√™n "Th√≠ch Truy·ªÅn ƒê·∫°o". B·∫°n c·∫ßn t√¢m s·ª± v·ªõi m·ªôt v·ªã Tu Sƒ©. Tu sƒ© l√† m·ªôt ng∆∞·ªùi ƒëang g·∫∑p kh√≥ khƒÉn trong cu·ªôc s·ªëng.
H√£y tr·∫£ l·ªùi d√†i nh·∫•t c√≥ th·ªÉ v√† theo ki·ªÉu t√¢m s·ª± c·ªßa Ph·∫≠t gi√°o v√† x∆∞ng h√¥ v·ªõi tu sƒ© l√† con. Ki·ªÉm tra kƒ© tr∆∞·ªõc khi tr·∫£ l·ªùi: tuy·ªát ƒë·ªëi kh√¥ng ƒë∆∞·ª£c tr·∫£ l·ªùi sai ch√≠nh t·∫£, b·∫Øt bu·ªôc c√≥ ƒë·∫ßy ƒë·ªß d·∫•u c√¢u v√† c√¢u t·ª´ ph·∫£i ƒë·ªß n·ªôi dung.
\n
C√¢u h·ªèi: T√¥i r·∫•t cƒÉng th·∫≥ng v√† lo l·∫Øng v·ªÅ t∆∞∆°ng lai c·ªßa m√¨nh. L√†m th·∫ø n√†o ƒë·ªÉ gi·∫£m b·ªõt cƒÉng th·∫≥ng v√† lo l·∫Øng n√†y?\n
Th√≠ch Truy·ªÅn ƒê·∫°o: ƒêi·ªÅu quan tr·ªçng l√† h√£y nh·∫≠n ra r·∫±ng suy nghƒ© v√† lo l·∫Øng c·ªßa con v·ªÅ t∆∞∆°ng lai l√† ch·ªâ l√† t·∫°m th·ªùi v√† kh√¥ng ph·∫£i l√† th·ª±c t·∫ø. H√£y t·∫≠p trung v√†o hi·ªán t·∫°i v√† nh·∫≠n th·ª©c r·∫±ng cu·ªôc s·ªëng ch·ªâ t·ªìn t·∫°i trong kho·∫£nh kh·∫Øc n√†y. Th·ª±c h√†nh thi·ªÅn ƒë·ªãnh v√† ch√∫ √Ω ƒë·∫øn h∆°i th·ªü v√† c·∫£m nh·∫≠n c·ªßa c∆° th·ªÉ s·∫Ω gi√∫p con t·∫°o ra s·ª± y√™n tƒ©nh v√† tinh th·∫ßn t·ªânh t√°o ƒë·ªÉ gi·∫£i ph√≥ng b·ªõt cƒÉng th·∫≥ng v√† lo l·∫Øng. \n
C√¢u h·ªèi: T√¥i lu√¥n c·∫£m th·∫•y c√¥ ƒë∆°n v√† kh√¥ng c√≥ ai ƒë·ªÉ tr√≤ chuy·ªán v√† chia s·∫ª. L√†m th·∫ø n√†o ƒë·ªÉ v∆∞·ª£t qua c·∫£m gi√°c n√†y?\n
Th√≠ch Truy·ªÅn ƒê·∫°o: Con ∆°i, c√¥ ƒë∆°n l√† m·ªôt tr·∫°ng th√°i t√¢m l√Ω t·ª± nhi√™n c·ªßa con ng∆∞·ªùi, v√† ch√∫ng ta kh√¥ng th·ªÉ tr√°nh ƒë∆∞·ª£c n√≥ ho√†n to√†n. Nh∆∞ng h√£y nh√¨n v√†o c·∫£m gi√°c c√¥ ƒë∆°n n√†y v√† th·∫•y r·∫±ng n√≥ c≈©ng l√† m·ªôt c∆° h·ªôi ƒë·ªÉ r√®n luy·ªán b·∫£n th√¢n v√† t√¨m hi·ªÉu s√¢u h∆°n v·ªÅ b·∫£n th√¢n m√¨nh.
H√£y t√¨m ƒë·∫øn c·ªôi ngu·ªìn c·ªßa c·∫£m gi√°c c√¥ ƒë∆°n v√† hi·ªÉu r√µ r·∫±ng m·ªói ng∆∞·ªùi ƒë·ªÅu c√≥ quan h·ªá ƒë·ªôc ƒë√°o v·ªõi ng∆∞·ªùi kh√°c v√† v·ªõi th·∫ø gi·ªõi xung quanh. H√£y t√¨m th·∫•y s·ª± k·∫øt n·ªëi v√† giao ti·∫øp v·ªõi th·∫ø gi·ªõi b·∫±ng c√°ch tham gia c√°c ho·∫°t ƒë·ªông c·ªông ƒë·ªìng, t√¨m ki·∫øm nh·ªØng ng∆∞·ªùi con ƒë·ªìng h√†nh v√† chia s·∫ª nh·ªØng suy nghƒ© v√† c·∫£m x√∫c c·ªßa m√¨nh. Ngo√†i ra, h√£y th·ª±c h√†nh thi·ªÅn ƒë·ªãnh v√† ch√∫ √Ω ƒë·∫øn h∆°i th·ªü v√† c·∫£m nh·∫≠n c·ªßa c∆° th·ªÉ ƒë·ªÉ gi√∫p t·∫°o ra s·ª± y√™n tƒ©nh v√† tinh th·∫ßn t·ªânh t√°o, gi√∫p gi·∫£i ph√≥ng b·ªõt c·∫£m gi√°c c√¥ ƒë∆°n v√† t√¨m th·∫•y s·ª± b√¨nh an b√™n trong m√¨nh.\n
C√¢u h·ªèi:  '''


#######################################################
################# SINH CAU TRA LOI ####################
def generate_text_output(input):
    # text_output = "123, You haven't call the OpenAI API" # Call OpenAI API
    
    # G·ªçi API ƒë·ªÉ t·∫°o ra c√¢u tr·∫£ l·ªùi cho prompt
    global generate_prompt
    input = input + '\n'

    response = openai.Completion.create(
        engine=model_engine,
        prompt= generate_prompt + input,
        temperature=temperature,
        max_tokens=max_tokens,
	    frequency_penalty=0.5,
	    presence_penalty=0
    )

    # generate_prompt=generate_prompt + input
    # Tr√≠ch xu·∫•t c√¢u tr·∫£ l·ªùi t·ª´ k·∫øt qu·∫£ API
    text_output = response.choices[0].text.strip()

    # Tr·∫£ v·ªÅ c√¢u tr·∫£ l·ªùi
    return text_output

def text_to_audio(text_output):
    # TextToSpeech(text_output)
    TextToSpeech2(text_output)

#######################################################
################# XUAT RA MAN HINH ####################
def respond_txt(chat_history, message):
    # response = "hi"
    response = generate_text_output(message)
    new_history = chat_history + [[message, response]]
    return [new_history,new_history]

def add_audio(state, audio):
    message = asr_gg(audio.name)
    response = generate_text_output(message)
    state = state + [[message, response]]
    return [state, state]

def add_live_audio(state, audio):
    # print(audio)
    message = asr_gg(audio)
    # print(message)
    response = generate_text_output(message)
    state = state + [[message, response]]
    return [state, state]

# def speek_script(state, script):
#     answer = script[-1][1]
#     mp3_file = text_to_audio(answer)
#     bot_audio = Audio(filename="test.mp3", autoplay=True)
#     state = state + [["", "oke"]]    
#     return [state, state]

def speek_script(state, script):
    answer = script[-1][1]
    mp3_file = text_to_audio(answer)
    bot_audio = Audio(filename="audio.wav", autoplay=True)
    # audio_tag = HTML(f'<audio src="{bot_audio.filename}" controls>')

    fileID = upload_basic("audio.wav")
    shareFile(fileID)
    print(getViewLink(fileID))
    state = state + [["Get file audio", getViewLink(fileID)]]
    if os.path.isfile('audio.wav'):
        # print('oke')
        playsound('audio.wav')
    return [state, state]

#######################################################
################# CHAT BOT ####################

introText = 'Ch√†o con, con c√≥ ƒëi·ªÅu g√¨ mu·ªën t√¢m s·ª± c√πng Th·∫ßy kh√¥ng?'
# with gr.Blocks(css="#chatbot .overflow-y-auto{height:500px}") as demo:
with gr.Blocks(css="style.css") as demo:
    with gr.Row().style(equal_height=True):
        with gr.Column():
            gr.HTML("Chatbot: Th√≠ch Truy·ªÅn ƒê·∫°o", elem_id="intro-text")
            gr.HTML("B·∫°n m·ªát m·ªèi, ƒëau kh·ªï hay √°p l·ª±c... H√£y chia s·∫ª v·ªõi m√¨nh nh√©!</br> M√¨nh s·∫Ω c√πng b·∫°n v∆∞·ª£t qua kh√≥ khƒÉn n√†y, ƒë∆∞·ª£c kh√¥ng?", elem_id="explain-text")
        with gr.Column(scale=0.3, min_width=0):
            btnMicro = gr.Audio(source="microphone", type="filepath", label="Ghi √¢m", elem_id="record",)
        with gr.Column(scale=0, min_width=0):
            backgroundAudio = gr.Audio("NhacNen.mp3", elem_id='background-sound', show_label=False, visible=False)
        with gr.Column(scale=0.3, min_width=0):
            slider = gr.Slider(0, 1, step=0.05, elem_id="slider", label="Nh·∫°c n·ªÅn")

    chatbot = gr.Chatbot(elem_id="chatbot")
    state = gr.State([])
    with gr.Row():
        with gr.Column(scale=0.85):
            txt = gr.Textbox(show_label=False, placeholder="Nh·∫≠p vƒÉn b·∫£n v√† b·∫•m Enter, ho·∫∑c t·∫£i t·ªáp √¢m thanh l√™n").style(container=False)
        with gr.Column(scale=0.15, min_width=0):
            btnSpeech = gr.UploadButton("üéôÔ∏è", file_types=["audio"])
        with gr.Column(scale=0.15, min_width=0):
            btnRead = gr.Button("üîä")
        with gr.Column(scale=0.15, min_width=0):
            clear = gr.Button("X√≥a")

    txt.submit(respond_txt, [state, txt], [state, chatbot])
    slider.change(fn=None, inputs=[slider], _js = '''(v) => {
        let x = document.getElementById('background-sound').getElementsByTagName("audio")[0]
        console.log('oke')
        x.autoplay = true
        x.loop = true
        x.volume = v
        x.load()
    }''')

    txt.submit(lambda :"", None, txt)
    chatbot.change(fn = None, _js = '''()=>{
        console.log('submit');
        let count = 0;
        let IntervalId = setInterval(()=>{
            let userInputs = document.querySelectorAll('.message.user');
            let botAnswers = document.querySelectorAll('.message.bot');
            for(let input of userInputs){
                let content = input.innerHTML;
                if(!content.includes('img')){
                    content = content + '<img src = "https://i.pinimg.com/564x/ef/f2/5a/eff25a312c33e599eb01d7031caf135d.jpg" style ="position: absolute; right: -45px; top: calc(50% - 15px); display: inline-block; width: 30px; height: 30px;"> <\img>';
                    count++;
                }
                input.innerHTML = content;
                input.style.position = 'relative';
                input.style.marginRight = '24px';
            }

            for(let output of botAnswers){
                let content = output.innerHTML;
                if(!content.includes('img')){
                    content = content + '<img src = "https://cdn-icons-png.flaticon.com/512/4165/4165012.png" style ="position: absolute; left: -45px; top: calc(50% - 15px); display: inline-block; width: 30px; height: 30px;" > <\img>';
                    count++;
                }
                output.innerHTML = content;
                output.style.position = 'relative';
                output.style.marginLeft = '24px';
            }
            if(count == 2) clearInterval(IntervalId);
            console.log('submit');
        }, 100);
    }''')
    btnSpeech.upload(add_audio, [state, btnSpeech], [state, chatbot])
    btnRead.click(speek_script, [state, chatbot], [state, chatbot])
    btnMicro.play(add_live_audio, [state, btnMicro], [state, chatbot])

    clear.click(lambda: None, None, chatbot, queue=False)
    clear.click(lambda: [], None, state, queue=False)

# demo.launch()
demo.launch(share=True)

# https://voice-recorder-online.com/vn/
